{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This is a sample code to assist you with vectorising the 'Train' dataset for your assignment 2.\n",
    "\n",
    "First we read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 6099\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    replacements = {\n",
    "        # Replace links wih URL\n",
    "        r'(http\\S+)': 'URL',\n",
    "\n",
    "        # Replace @'s with USERNAME\n",
    "        r'@[A-Za-z0-9]+': 'USERNAME',\n",
    "\n",
    "        # Replace characters repeated more than with two of the characters\n",
    "        r'([a-zA-Z])(\\1{2,})': '\\\\1\\\\1',\n",
    "\n",
    "        # Remove incorrectly encoded emojis.\n",
    "        r'ï£¿...': '',\n",
    "\n",
    "        '[0-9]+': '',\n",
    "    }\n",
    "    for original, replace in replacements.items():\n",
    "        text = re.sub(original, replace, text)\n",
    "    return text\n",
    "\n",
    "# data cleaning\n",
    "\n",
    "X_test_raw = test_data['text'].apply(preprocess)\n",
    "X_test_raw = X_test_raw.apply(preprocess)\n",
    "\n",
    "#check the result\n",
    "print(\"Test length:\", len(X_test_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out with test size 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_raw, Y_train,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW applied on testing data, training data and develop data\n",
    "BoW_vectorizer = CountVectorizer()\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "x_train_BoW = BoW_vectorizer.fit_transform(X_train)\n",
    "x_test_BoW = BoW_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-R Accuracy: 0.5882892524078887 Time: 0.5237390995025635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Accuracy: 0.6595321816236049 Time: 27.318728923797607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Accuracy: 0.6280385262192325 Time: 13.816276788711548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fit into linear models\n",
    "models = [DummyClassifier(strategy='most_frequent'),\n",
    "          MultinomialNB(),\n",
    "          LinearSVC(),\n",
    "          DecisionTreeClassifier(),\n",
    "          KNeighborsClassifier(),\n",
    "          LogisticRegression()]\n",
    "titles = ['Zero-R',\n",
    "          'MNB',\n",
    "          'LinearSVC',\n",
    "          'Decision Tree',\n",
    "          'KNN',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    start = time.time()\n",
    "    model.fit(x_train_BoW.todense(), y_train)\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    acc = model.score(x_test_BoW.todense(), y_test)\n",
    "    print(title, \"Accuracy:\", acc, 'Time:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Tfidf Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(C=1).fit(tf_x_train, y_train)\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(tf_x_train, y_train)\n",
    "    print(\"Accuracy for C=%s: %s\"\n",
    "          % (c, accuracy_score(y_test, lr.predict(tf_x_test))))\n",
    "\n",
    "mnb = MultinomialNB().fit(tf_x_train, y_train)\n",
    "print(mnb.score(tf_x_test, y_test))\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(tf_x_train, y_train)\n",
    "print(clf.score(tf_x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_X_train = vectorizer.fit_transform(X_train_raw)\n",
    "tf_X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "model_lr = LogisticRegression(multi_class='ovr')\n",
    "model_lr.fit(tf_X_train, Y_train)\n",
    "\n",
    "prediction = model_lr.predict(tf_X_test.todense())\n",
    "pre = pd.DataFrame(prediction, columns=['sentiment'], index=test_data['id'])\n",
    "pre.index.name = 'id'\n",
    "pre.to_csv(r\"tfidf_prediction_cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# apply k best on tfidf \n",
    "kbest = SelectKBest(chi2, k=500).fit(tf_x_train, y_train)\n",
    "kbest_train_x = kbest.transform(tf_x_train)\n",
    "kbest_test_x = kbest.transform(tf_x_test)\n",
    "\n",
    "mnb = MultinomialNB().fit(kbest_train_x, y_train)\n",
    "print(mnb.score(kbest_test_x, y_test))\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(kbest_train_x, y_train)\n",
    "print(clf.score(kbest_test_x, y_test))\n",
    "\n",
    "final_tfidf = LogisticRegression(C=1)\n",
    "final_tfidf.fit(kbest_train_x, y_train)\n",
    "print(final_tfidf.score(kbest_test_x, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the created vocabulary for the given dataset in a separate file\n",
    "vocab_dict = BoW_vectorizer.vocabulary_\n",
    "output_pd = pd.DataFrame(list(vocab_dict.items()), columns=['word', 'count'])\n",
    "output_pd.T.to_csv('BoW-vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# apply k best on BoW \n",
    "kbest = SelectKBest(chi2, k=500).fit(X_train_BoW, Y_train)\n",
    "kbest_train_X = kbest.transform(X_train_BoW)\n",
    "kbest_test_X = kbest.transform(X_test_BoW)\n",
    "\n",
    "# training dataset\n",
    "kbest = SelectKBest(chi2, k=700).fit(x_train_BoW, y_train)\n",
    "kbest_train_x = kbest.transform(x_train_BoW)\n",
    "kbest_test_x = kbest.transform(x_test_BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# training and development set\n",
    "x_train = kbest_train_x\n",
    "x_test = kbest_test_x\n",
    "# training and testing set\n",
    "X_train = kbest_train_X\n",
    "X_test = kbest_test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Adapting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the 10_fold_Cross_Validation with 4 models(LinearSVC, Decision Tree, KNN, Logistic Regression)\n",
    "models = [LinearSVC(),\n",
    "          DecisionTreeClassifier(),\n",
    "          KNeighborsClassifier(),\n",
    "          LogisticRegression()]\n",
    "titles = ['LinearSVC',\n",
    "          'Decision Tree',\n",
    "          'KNN',\n",
    "          'Logistic Regression']\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    start = time.time()\n",
    "    acc = np.mean(cross_val_score(model, x_train, y_train, cv=20))\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(title, \"Accuracy:\", acc, 'time:', t)\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    start = time.time()\n",
    "    acc = np.mean(cross_val_score(model, x_test, y_test, cv=20))\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(title, \"Accuracy:\", acc, 'time:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.logspace(-2, 2, 10)\n",
    "train_scores, valid_scores = validation_curve(LinearSVC(), x_train, y_train,\n",
    "                                              param_name='C',\n",
    "                                              param_range=param_range, cv=5,\n",
    "                                              n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mean_train_scores = np.mean(train_scores, axis=1)\n",
    "std_train_scores = np.std(train_scores, axis=1)\n",
    "mean_valid_scores = np.mean(valid_scores, axis=1)\n",
    "std_valid_scores = np.std(valid_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.semilogx(param_range, mean_train_scores, label=\"Training score\",\n",
    "             color='red')\n",
    "plt.fill_between(param_range, mean_train_scores - std_train_scores,\n",
    "                 mean_train_scores + std_train_scores, alpha=0.2, color=\"red\")\n",
    "\n",
    "plt.semilogx(param_range, mean_valid_scores, label=\"cross validation score\",\n",
    "             color='blue')\n",
    "plt.fill_between(param_range, mean_valid_scores - std_valid_scores,\n",
    "                 mean_valid_scores + std_valid_scores, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"Validation curve for hyperparameter C in LinearSVC\")\n",
    "plt.xlabel(\"C in log scale\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "best_C = param_range[mean_valid_scores.argmax()]\n",
    "best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## rbf SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "              \"C\": [10, 100, 1000, 10000]}\n",
    "\n",
    "grd = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1, cv=3)\n",
    "\n",
    "grd.fit(x_train, y_train)\n",
    "print(grd.best_params_)\n",
    "\n",
    "#\n",
    "svc_rbf = SVC(kernel=\"rbf\", gamma=0.001, C=1000).fit(x_train, y_train)\n",
    "print(grd.best_score_)\n",
    "print(svc_rbf.score(x_train, y_train))\n",
    "print(svc_rbf.score(x_test, y_test))\n",
    "print(classification_report(y_test, svc_rbf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate SVC\n",
    "param_range = np.logspace(-2, 2, 10)\n",
    "train_scores_rbf, valid_scores_rbf = validation_curve(\n",
    "    SVC(max_iter=10000, kernel=\"rbf\", gamma=0.001),\n",
    "    x_train,\n",
    "    y_train,\n",
    "    param_name='C',\n",
    "    param_range=param_range,\n",
    "    cv=3,\n",
    "    n_jobs=-1, verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Graphing helper\n",
    "def val_curve(param_range, train_scores, valid_scores, model_name):\n",
    "    mean_train_scores = np.mean(train_scores, axis=1)\n",
    "    std_train_scores = np.std(train_scores, axis=1)\n",
    "    mean_valid_scores = np.mean(valid_scores, axis=1)\n",
    "    std_valid_scores = np.std(valid_scores, axis=1)\n",
    "    plt.semilogx(param_range, mean_train_scores, label=\"Training score\",\n",
    "                 color='red')\n",
    "    plt.fill_between(param_range, mean_train_scores - std_train_scores,\n",
    "                     mean_train_scores + std_train_scores, alpha=0.2,\n",
    "                     color=\"red\")\n",
    "\n",
    "    plt.semilogx(param_range, mean_valid_scores,\n",
    "                 label=\"cross validation score\",\n",
    "                 color='blue')\n",
    "    plt.fill_between(param_range, mean_valid_scores - std_valid_scores,\n",
    "                     mean_valid_scores + std_valid_scores, alpha=0.2,\n",
    "                     color=\"blue\")\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f\"Validation curve for hyperparameter C in {model_name}\")\n",
    "    plt.xlabel(\"C in log scale\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "    best_C = param_range[mean_valid_scores.argmax()]\n",
    "    print(best_C)\n",
    "\n",
    "\n",
    "val_curve(param_range, train_scores_rbf, valid_scores_rbf, \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Random Forests\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {\"n_estimators\": [10, 25, 50, 75, 100, 150, 200],\n",
    "              \"max_depth\": [10, 25, 50, 75, 100, 150, 200],\n",
    "              \"criterion\": [\"entropy\", \"gini\"],\n",
    "              }\n",
    "grd = GridSearchCV(estimator=RandomForestClassifier(random_state=1, n_jobs=-1),\n",
    "                   param_grid=parameters, n_jobs=-1, cv=3)\n",
    "grd.fit(x_train, y_train)\n",
    "print(grd.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Instantiate Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=75,\n",
    "    n_estimators=150).fit(x_train, y_train)\n",
    "\n",
    "print(random_forest.score(x_train, y_train))\n",
    "print(random_forest.score(x_test, y_test))\n",
    "print(classification_report(y_test, random_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# use grid search find optimal c for logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_lr = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 100],\n",
    "            'multi_class': ['multinomial', 'ovr'],\n",
    "            }\n",
    "gs_lr = GridSearchCV(LogisticRegression(), param_lr, cv=5, n_jobs=1,\n",
    "                     verbose=11)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"parameters:\")\n",
    "print(param_lr)\n",
    "\n",
    "gs_lr.fit(x_train, y_train)\n",
    "print(\"Best score: 40. 3f\" % gs_lr.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_param_lr = gs_lr.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(param_lr.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_param_lr[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lr_scores = gs_lr.cv_results_['mean_test_score'].reshape(7, 2)\n",
    "sns.heatmap(lr_scores, xticklabels=param_lr['multi_class'],\n",
    "            yticklabels=param_lr['C'], cmap='Blues')\n",
    "\n",
    "b, t = plt.ylim()  # discover the values for bottom and top\n",
    "b += 0.5  # Add 0.5 to the bottom\n",
    "t -= 0.5  # Subtract 0.5 from the top\n",
    "plt.ylim(b, t)  # update the ylim(bottom, top) values\n",
    "plt.title(\"Grid Search results of Logistic Regression\")\n",
    "plt.xlabel(\"multi class\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# logistic heatmap\n",
    "lr = LogisticRegression(C=1).fit(x_train, y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "\n",
    "matrix_lr = confusion_matrix(y_test, lr_pred)\n",
    "print(classification_report(y_test, lr_pred))\n",
    "sns.heatmap(matrix_lr, cmap='Blues', annot=True, fmt='d')\n",
    "plt.title(\"Logistic Regression confusion matrix and heatmap\")\n",
    "plt.xlabel(\"Predicted classes\")\n",
    "plt.ylabel(\"Actual classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#voting\n",
    "base_classifiers = [('sgd', SGDClassifier()),\n",
    "                    ('dt', DecisionTreeClassifier()),\n",
    "                    ('lr', LogisticRegression(C=1, multi_class='multinomial')),\n",
    "                    ('mnb', MultinomialNB()),\n",
    "                    (' svc', LinearSVC(C=10))]\n",
    "voting = VotingClassifier(estimators=base_classifiers, voting='hard')\n",
    "voting.fit(x_train, y_train)\n",
    "print(\"voting accuracy\")\n",
    "cross_val_score(voting, x_train, y_train, cv=5).mean(), voting.score(x_test,\n",
    "                                                                     y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# bagging\n",
    "DT = DecisionTreeClassifier()\n",
    "bagging_one = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                n_estimators=10,\n",
    "                                max_samples=1.0, max_features=1.0)\n",
    "bagging_two = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                n_estimators=10,\n",
    "                                max_samples=0.5, max_features=1.0)\n",
    "bagging_three = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                  n_estimators=10,\n",
    "                                  max_samples=0.5, max_features=0.5)\n",
    "\n",
    "DT.fit(x_train, y_train)\n",
    "bagging_one.fit(x_train, y_train)\n",
    "bagging_two.fit(x_train, y_train)\n",
    "bagging_three.fit(x_train, y_train)\n",
    "\n",
    "print(\"DT:\", DT.score(x_test, y_test))\n",
    "print(\"Option 1: bagging Accuracy:\", bagging_one.score(x_test, y_test))\n",
    "print(\"Option 2: bagging Accuracy:\", bagging_two.score(x_test, y_test))\n",
    "print(\"Option 3: bagging Accuracy:\", bagging_three.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#voting\n",
    "base_classifiers = [('sgd', SGDClassifier()),\n",
    "                    ('dt', DecisionTreeClassifier()),\n",
    "                    ('lr',\n",
    "                     LogisticRegression(C=0.5, multi_class='multinomial')),\n",
    "                    ('mnb', MultinomialNB()),\n",
    "                    (' svc', LinearSVC(C=10))]\n",
    "voting = VotingClassifier(estimators=base_classifiers, voting='hard')\n",
    "\n",
    "voting.fit(kbest_train_X.todense(), Y_train)\n",
    "\n",
    "prediction = voting.predict(kbest_test_X.todense())\n",
    "#print(\"Stacker predict done\")\n",
    "\n",
    "print(prediction)\n",
    "pre = pd.DataFrame(prediction, columns=['sentiment'], index=test_data['id'])\n",
    "pre.index.name = 'id'\n",
    "pre.to_csv(r\"voting_prediction_cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_jobs=-1, n_estimators=100, verbose=1).fit(\n",
    "    x_train, y_train)\n",
    "print(rf.score(x_test, y_test))\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, n_estimators=10, verbose=1).fit(x_train,\n",
    "                                                                       y_train)\n",
    "print(rf.score(x_test, y_test))\n",
    "\n",
    "rf_pred = rf.predict(x_test)\n",
    "matrix_rf = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "print(matrix_rf)\n",
    "sns.heatmap(matrix_rf, cmap='Greens', annot=True, fmt='d')\n",
    "plt.title(\"Random Forest confusion matrix and heatmap\")\n",
    "plt.xlabel(\"Predicted classes\")\n",
    "plt.ylabel(\"Actual classes\")\n",
    "\n",
    "#ada\n",
    "ada = AdaBoostClassifier().fit(x_train, y_train)\n",
    "print(ada.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# stacking code from prac 8\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "\n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        assert yhats.shape[0] == X.shape[0]\n",
    "        return yhats\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)\n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# base calssifier to be chosen # lr/multinomial\n",
    "classifiers = [LogisticRegression(),\n",
    "               MultinomialNB()]\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB']\n",
    "\n",
    "# three meta classifiers\n",
    "meta_classifier_lr = LogisticRegression(C=1)\n",
    "stacker_lr = StackingClassifier(classifiers, meta_classifier_lr)\n",
    "\n",
    "meta_classifier_mnb = MultinomialNB()\n",
    "stacker_mnb = StackingClassifier(classifiers, meta_classifier_mnb)\n",
    "\n",
    "meta_classifier_svc = LinearSVC(C=10)\n",
    "stacker_svc = StackingClassifier(classifiers, meta_classifier_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "stacker_lr.fit(x_train.todense(), y_train)\n",
    "end = time.time()\n",
    "t = end - start\n",
    "acc_lr = stacker_lr.score(x_test.todense(), y_test)\n",
    "print('\\nStacker Accuracy (Logistic Regression):', acc_lr, 'Time:', t)\n",
    "\n",
    "start = time.time()\n",
    "stacker_mnb.fit(x_train.todense(), y_train)\n",
    "end = time.time()\n",
    "t = end - start\n",
    "acc_mnb = stacker_mnb.score(x_test.todense(), y_test)\n",
    "print('\\nStacker Accuracy (Multinomial Regression):', acc_mnb, 'Time:', t)\n",
    "\n",
    "start = time.time()\n",
    "stacker_svc.fit(x_train.todense(), y_train)\n",
    "end = time.time()\n",
    "t = end - start\n",
    "acc_svc = stacker_svc.score(x_test.todense(), y_test)\n",
    "print('\\nStacker Accuracy (LinearSVC):', acc_svc, 'Time:', t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stacker_lr.fit(kbest_train_X.todense(), Y_train)\n",
    "stacker_svc.fit(kbest_train_X.todense(), Y_train)\n",
    "\n",
    "prediction = stacker_svc.predict(kbest_test_X.todense())\n",
    "pre = pd.DataFrame(prediction, columns=['sentiment'], index=test_data['id'])\n",
    "pre.index.name = 'id'\n",
    "pre.to_csv(r\"svc_stacker_prediction_cv.csv\")\n",
    "\n",
    "prediction = stacker_lr.predict(kbest_test_X.todense())\n",
    "pre = pd.DataFrame(prediction, columns=['sentiment'], index=test_data['id'])\n",
    "pre.index.name = 'id'\n",
    "pre.to_csv(r\"lr_stacker_prediction_cv.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
